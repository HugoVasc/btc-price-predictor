{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 18:44:18.191772: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-29 18:44:18.193605: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-29 18:44:18.198646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732916658.207055    1460 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732916658.209967    1460 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 18:44:18.219681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from crypto_trading_env import CryptoTradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>m_avg_7</th>\n",
       "      <th>m_avg_25</th>\n",
       "      <th>m_avg_99</th>\n",
       "      <th>close_diff</th>\n",
       "      <th>m_avg_7_diff</th>\n",
       "      <th>m_avg_25_diff</th>\n",
       "      <th>m_avg_99_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3849.216309</td>\n",
       "      <td>3947.981201</td>\n",
       "      <td>3817.409424</td>\n",
       "      <td>3943.409424</td>\n",
       "      <td>3893.464722</td>\n",
       "      <td>3893.464722</td>\n",
       "      <td>3893.464722</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>0.012995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3931.048584</td>\n",
       "      <td>3935.685059</td>\n",
       "      <td>3826.222900</td>\n",
       "      <td>3836.741211</td>\n",
       "      <td>3874.556885</td>\n",
       "      <td>3874.556885</td>\n",
       "      <td>3874.556885</td>\n",
       "      <td>-0.027050</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.004856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3832.040039</td>\n",
       "      <td>3865.934570</td>\n",
       "      <td>3783.853760</td>\n",
       "      <td>3857.717529</td>\n",
       "      <td>3870.347046</td>\n",
       "      <td>3870.347046</td>\n",
       "      <td>3870.347046</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.001087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3851.973877</td>\n",
       "      <td>3904.903076</td>\n",
       "      <td>3836.900146</td>\n",
       "      <td>3845.194580</td>\n",
       "      <td>3865.316553</td>\n",
       "      <td>3865.316553</td>\n",
       "      <td>3865.316553</td>\n",
       "      <td>-0.003246</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3836.519043</td>\n",
       "      <td>4093.297363</td>\n",
       "      <td>3826.513184</td>\n",
       "      <td>4076.632568</td>\n",
       "      <td>3900.535889</td>\n",
       "      <td>3900.535889</td>\n",
       "      <td>3900.535889</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.009112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open         High          Low        Close      m_avg_7  \\\n",
       "0  3849.216309  3947.981201  3817.409424  3943.409424  3893.464722   \n",
       "1  3931.048584  3935.685059  3826.222900  3836.741211  3874.556885   \n",
       "2  3832.040039  3865.934570  3783.853760  3857.717529  3870.347046   \n",
       "3  3851.973877  3904.903076  3836.900146  3845.194580  3865.316553   \n",
       "4  3836.519043  4093.297363  3826.513184  4076.632568  3900.535889   \n",
       "\n",
       "      m_avg_25     m_avg_99  close_diff  m_avg_7_diff  m_avg_25_diff  \\\n",
       "0  3893.464722  3893.464722    0.025989      0.012995       0.012995   \n",
       "1  3874.556885  3874.556885   -0.027050     -0.004856      -0.004856   \n",
       "2  3870.347046  3870.347046    0.005467     -0.001087      -0.001087   \n",
       "3  3865.316553  3865.316553   -0.003246     -0.001300      -0.001300   \n",
       "4  3900.535889  3900.535889    0.060189      0.009112       0.009112   \n",
       "\n",
       "   m_avg_99_diff  \n",
       "0       0.012995  \n",
       "1      -0.004856  \n",
       "2      -0.001087  \n",
       "3      -0.001300  \n",
       "4       0.009112  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet('../btc_hist_partitioned.parquet')\n",
    "data = data.reset_index(drop=True).drop(columns=['Date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CryptoTradingEnv(\n",
    "    dataset=data,\n",
    "    initial_balance=1000,\n",
    "    max_lose_percent=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/miniconda3/envs/postech/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1732916659.509793    1460 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 11\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='relu', input_shape=[n_inputs]), # try reku, elu, leaky relu\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax') # 3 actions: hold, buy, sell exclusively\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">963</span> (3.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m963\u001b[0m (3.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">963</span> (3.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m963\u001b[0m (3.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 0. 0.]], shape=(1, 3), dtype=float32) 0\n"
     ]
    }
   ],
   "source": [
    "# obs = env.reset()\n",
    "obs, _, _  = env.step(2)\n",
    "probas = model(obs.values[np.newaxis]) # predict the probability of going\n",
    "print(probas, np.argmax(probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open             3931.048584\n",
      "High             3935.685059\n",
      "Low              3826.222900\n",
      "Close            3836.741211\n",
      "m_avg_7          3874.556885\n",
      "m_avg_25         3874.556885\n",
      "m_avg_99         3874.556885\n",
      "close_diff         -0.027050\n",
      "m_avg_7_diff       -0.004856\n",
      "m_avg_25_diff      -0.004856\n",
      "m_avg_99_diff      -0.004856\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        ### Pós erro\n",
    "        if np.isnan(obs).any() or np.isinf(obs).any():\n",
    "            raise ValueError(\"obs contém valores NaN ou Inf\")\n",
    "        ###\n",
    "        probs = model(obs.values[np.newaxis]) # predict the probability of going left\n",
    "        if np.isnan(probs.numpy()).any():\n",
    "            print(f\"obs: {obs}\")\n",
    "            print(f\"probs: {probs}\")\n",
    "            raise ValueError(\"probs contém valores NaN\")\n",
    "        action = np.random.choice(a=len(probs.numpy().flatten()),\n",
    "                                   p=probs.numpy().flatten()) # random action based on the probability\n",
    "        y_target = tf.constant([[2.]]) - tf.cast(action, tf.float32)\n",
    "        print(f\"y_target: {y_target}\\nprobs: {probs}\")\n",
    "        loss = tf.reduce_mean(loss_fn(y_target[tf.newaxis], probs)) # loss function\n",
    "        ### Pós erro\n",
    "        if tf.math.is_nan(loss):\n",
    "            raise ValueError(\"Loss gerou NaN\")\n",
    "        ###\n",
    "    grads = tape.gradient(loss, model.trainable_variables) # compute the gradients\n",
    "    obs, reward, done = env.step(action) # apply the action\n",
    "    return obs, reward, done, grads\n",
    "\n",
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    max_steps = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        current_max_steps = 0\n",
    "        obs = env.reset()\n",
    "        for step in range(n_max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                if step > current_max_steps:\n",
    "                    current_max_steps = step\n",
    "                break\n",
    "        else: # executed if the loop ended without break\n",
    "            current_max_steps = n_max_steps\n",
    "        max_steps.append(current_max_steps)\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads, max_steps\n",
    "\n",
    "def discount_rewards(rewards, discount_rate):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1): # iterate over the rewards in reverse order\n",
    "        discounted[step] += discounted[step + 1] * discount_rate # add the discounted reward from the next step\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_rate):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_rate) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(1, 1, 1), output.shape=(1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m---> 10\u001b[0m     all_rewards, all_grads, max_steps \u001b[38;5;241m=\u001b[39m \u001b[43mplay_multiple_episodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes_per_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_max_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mmean rewards = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28msum\u001b[39m(rewards)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mrewards\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mall_rewards])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mmax steps = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmax(max_steps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mmean steps = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(max_steps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     all_final_rewards \u001b[38;5;241m=\u001b[39m discount_and_normalize_rewards(all_rewards, discount_rate)\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mplay_multiple_episodes\u001b[0;34m(env, n_episodes, n_max_steps, model, loss_fn)\u001b[0m\n\u001b[1;32m     32\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_max_steps):\n\u001b[0;32m---> 34\u001b[0m     obs, reward, done, grads \u001b[38;5;241m=\u001b[39m \u001b[43mplay_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     current_rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m     36\u001b[0m     current_grads\u001b[38;5;241m.\u001b[39mappend(grads)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mplay_one_step\u001b[0;34m(env, obs, model, loss_fn)\u001b[0m\n\u001b[1;32m     12\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(probs\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()),\n\u001b[1;32m     13\u001b[0m                            p\u001b[38;5;241m=\u001b[39mprobs\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;66;03m# random action based on the probability\u001b[39;00m\n\u001b[1;32m     14\u001b[0m y_target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m2.\u001b[39m]]) \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(action, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_target\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# loss function\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m### Pós erro\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mis_nan(loss):\n",
      "File \u001b[0;32m~/miniconda3/envs/postech/lib/python3.10/site-packages/keras/src/losses/losses.py:1721\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1716\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(ops\u001b[38;5;241m.\u001b[39mshape(y_true)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1717\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   1718\u001b[0m         label_smoothing \u001b[38;5;241m/\u001b[39m num_classes\n\u001b[1;32m   1719\u001b[0m     )\n\u001b[0;32m-> 1721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/postech/lib/python3.10/site-packages/keras/src/ops/nn.py:1474\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((target, output)):\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CategoricalCrossentropy(\n\u001b[1;32m   1472\u001b[0m         from_logits\u001b[38;5;241m=\u001b[39mfrom_logits, axis\u001b[38;5;241m=\u001b[39maxis\n\u001b[1;32m   1473\u001b[0m     )\u001b[38;5;241m.\u001b[39msymbolic_call(target, output)\n\u001b[0;32m-> 1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/postech/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:580\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m     )\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(1, 1, 1), output.shape=(1, 3)"
     ]
    }
   ],
   "source": [
    "n_iterations = 150\n",
    "n_episodes_per_update = 5\n",
    "n_max_steps = len(data) - 1\n",
    "discount_rate = 0.95\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.categorical_crossentropy\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    all_rewards, all_grads, max_steps = play_multiple_episodes(env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
    "    print(f\"Iteration {iteration}:\\n\\tmean rewards = {np.mean([sum(rewards) for rewards in all_rewards])};\\n\\tmax steps = {np.max(max_steps)};\\n\\tmean steps = {np.mean(max_steps)}\")\n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_rate)\n",
    "    all_mean_grads = []\n",
    "    for var_index in range(len(model.trainable_variables)): # iterate over all trainable variables\n",
    "        mean_grads = tf.reduce_mean([final_reward * all_grads[episode_index][step][var_index] # mean gradient for this variable\n",
    "                                     for episode_index, final_rewards in enumerate(all_final_rewards)\n",
    "                                     for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables)) # apply the gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
